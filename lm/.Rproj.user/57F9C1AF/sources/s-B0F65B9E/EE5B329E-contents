library(stringr)
library(reshape2)
library(ggplot2)
library(dplyr)
library(stringr)
library(jtools)
library(ggstance)
library(sjPlot)
library(sjmisc)
library(sjlabelled)
library(ppcor)
library(tibble)

rm(list = ls()) # clean the variables environment

#### PARAMETERS ######
#### parameters to set before we run the code ####:
# which file to analyze:
file = read.csv('international_first_run all_condotions.csv')
# what conditions will be the predictors (names should be as they appear in the file)
predictors = c("SGPT", "VGG")
# What are the predictors' names (these names will be used in the figures and models)
# (you can choose names that are different from the original names in the file, but keep the same order as you entered the conditions above)
predictors_names = c("SGPT", "VGG")
# what conditions will be predicted (names should be as they appear in the file)
predicted = c("visual_pics")
# What are the predicted variables' names 
# (you can choose names that are different from the original names in the file, but keep the same order as you entered the conditions above)
predicted_names = c("perception")

# please read (all of) this:
# you can also choose the colors of the bars of the plot if you want, 
# by changing the values of colors in the pallet
# if you don't want to choose the colors please set the pallet to 'null' (remove the comment from that line)
# if you keep the pallet, 
# the code will choose the first n colors from it (according to the number of predictors)
# in the plot - R will arrange the predictors according to the ABC, so take this into account when you name the
# predictors (in the 'predictors names' vector and in the colors pallet)
# because they wont necessarily be aligned
# the usual colors we choose for predictors are: 
# for semantic predictor- red ('brown3' in the pallet)
# for visual predictor- blue ('dodgerblue3' in the pallet)
# for visual-semantic predictor- purple ('mediumorchid3' in the pallet)

# color_pallet = c('mediumorchid3','brown3','dodgerblue3')
color_pallet = c('brown3','dodgerblue3')

#################################################

# clean and prepare the data:
file$condition = sub(".*/./", "", file$condition) 
# we only want to analyze trials that should not be rejected
relevant_data = subset(file, reject_trial == FALSE)
# we analyze the averaged data across participants in each condition:
relevant_data <- relevant_data %>% group_by(pair, condition) %>% summarise(keyPressed = mean(keyPressed))


# we will create a df that we can use to conduct the ml:
pairs = data.frame(unique(relevant_data$pair))
colnames(pairs) = c('pair')
for (i in (1:length(predictors))){
  predictor = predictors[i]
  predictor_name = predictors_names[i]
  predictor_df = subset(relevant_data, condition == predictor)
  if (all(pairs$pair == predictor_df$pair)){ # very important: we make sure all pairs are in the same order
    pairs[predictor_name] = predictor_df$keyPressed
  }
}

predictors_df =  pairs

for (i in (1:length(predicted))){
  predicted_var = predicted[i]
  predicted_name = predicted_names[i]
  predicted_df = subset(relevant_data, condition == predicted_var)
  predicted_df <- subset(predicted_df, pair %in% predictors_df$pair)
  predictors_df_unique <- subset(predictors_df, pair %in% predicted_df$pair)
  if (all(predictors_df_unique$pair == predicted_df$pair)){ # very important: we make sure all pairs are in the same order
    predictors_df_unique[predicted_name] = predicted_df$keyPressed
  }
}

pairs = predictors_df_unique

print(noquote("#### all correlations #######"))
print(noquote(" "))
correlations = cor(pairs[, c(predictors_names, predicted_names)])
print(correlations)
print(noquote(" "))

for (i in (1:length(predicted))){
  predicted_name = predicted_names[i]
  # specific correlations with this predicted variable:
  sub_correl = subset(correlations, select = predicted_names)
  sub_correl = subset(sub_correl, select = predicted_name)
  sub_correl = sub_correl[!(row.names(sub_correl) %in% predicted_names),]
  sub_correl= data.frame(sub_correl)
  sub_correl <- tibble::rownames_to_column(sub_correl, "predictor")
  
  #print lm results:
  print(noquote(" "))
  print(noquote(paste("####### predicting:", predicted_name, "########")))
  print(noquote(" "))
  general_formula = paste(predicted_name, '~')
  for (j in (1:(length(predictors)))){
    predictor = predictors_names[j]
    fmla <- as.formula(paste(predicted_name, predictor, sep = "~"))
    model = lm(fmla, data = pairs)
    sum = summ(model, scale = TRUE)
    print(noquote(" "))
    print(noquote(paste("#### normalized results single predictor:", predictor, "####")))
    print(noquote(" "))
    print(sum)
    if (j > 1){
      general_formula = paste(general_formula,predictor,sep = '+')  
    }else{
      general_formula = paste(general_formula,predictor)
    }
  }
  fmla <- as.formula(general_formula)
  model = lm(fmla, data = pairs)
  sum = summ(model, scale = TRUE)
  print(noquote(" "))
  print(noquote("##### normalized results multiple model ######"))
  print(noquote(" "))
  print(sum)
  
  #plot the normalized coefficents:
  sum_df = data.frame(sum$coeftable)
  sum_df = sum_df[-1,] # removing the intercept line
  normelized_betas = data.frame(row.names(sum_df), sum_df$Est.)
  colnames(normelized_betas) = c('predictor', 'normelized_beta')
  p<-ggplot(normelized_betas, aes(x=predictor, y=normelized_beta, fill=predictor)) +
    geom_bar(stat="identity", width = 0.5)+
    scale_fill_manual(values = head(color_pallet,3))+
    ggtitle(paste("Multiple regressio results of:", predicted_name))+
    theme_classic()+
    theme(axis.text.x=element_blank(), axis.title = element_text(size = 20),
          axis.text.y = element_text(size = 13))+ylim(-0.1,0.9)
  print(p)
  
  colnames(sub_correl) = c('predictor', 'correlation')
  p<-ggplot(sub_correl, aes(x=predictor, y=correlation, fill=predictor)) +
    geom_bar(stat="identity", width = 0.5)+
    scale_fill_manual(values = head(color_pallet,3))+
    ggtitle(paste("Correlations with:", predicted_name))+
    theme_classic()+
    theme(axis.text.x=element_blank(), axis.title = element_text(size = 20),
          axis.text.y = element_text(size = 13))+ylim(-0.1,0.9)
  print(p)
}


